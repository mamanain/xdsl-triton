{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import triton\n",
    "import triton.language as tl\n",
    "from triton.language.extra import libdevice\n",
    "\n",
    "DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def frexp(x_ptr, exp_ptr, mantissa_ptr, num_elements, BLOCK_SIZE: tl.constexpr):\n",
    "    pid = tl.program_id(axis=0)\n",
    "    block_start = pid * BLOCK_SIZE\n",
    "    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n",
    "    mask = offsets < num_elements\n",
    "\n",
    "    x = tl.load(x_ptr + offsets)\n",
    "\n",
    "    y = libdevice.ilogb(x) + 1\n",
    "    exponent = tl.where(x == 0, 0, y)\n",
    "    mantissa = tl.where(x == 0, 0, libdevice.ldexp(x, -y))\n",
    "\n",
    "    tl.store(exp_ptr + offsets, exponent, mask)\n",
    "    tl.store(mantissa_ptr + offsets, mantissa, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MLIR_ENABLE_DUMP=1\n",
      "env: MLIR_DUMP_PATH=dump.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.,  0., -5.,  0.,  0.,  0., -1.,  0., -2.,  0.], device='cuda:0')\n",
      "tensor([0.7981, 0.5167, 0.7978, 0.9401, 0.9459, 0.7967, 0.8300, 0.8203, 0.9162,\n",
      "        0.9096], device='cuda:0')\n",
      "The maximum difference between torch and triton is 0.0\n"
     ]
    }
   ],
   "source": [
    "%env MLIR_ENABLE_DUMP=1\n",
    "%env MLIR_DUMP_PATH=dump.txt\n",
    "!rm -rf ~/.triton\n",
    "\n",
    "torch.manual_seed(0)\n",
    "size = 10\n",
    "x = torch.rand(size, device=DEVICE)\n",
    "exp_ptr = torch.zeros(size, device=DEVICE)\n",
    "mantissa_ptr = torch.zeros(size, device=DEVICE)\n",
    "\n",
    "grid = lambda meta: (triton.cdiv(size, meta['BLOCK_SIZE']), )\n",
    "frexp[grid](x, exp_ptr, mantissa_ptr, size, 2)\n",
    "\n",
    "print(exp_ptr)\n",
    "print(mantissa_ptr)\n",
    "\n",
    "torch_mantissa, torch_exp = torch.frexp(x)\n",
    "\n",
    "print(f'The maximum difference between torch and triton is '\n",
    "      f'{torch.max(torch.max(torch.abs(torch_mantissa - mantissa_ptr)), torch.max(torch.abs(torch_exp - exp_ptr)))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def frexp_real(x_ptr, exp_ptr, mantissa_ptr, num_elements, BLOCK_SIZE: tl.constexpr):\n",
    "    pid = tl.program_id(axis=0)\n",
    "    block_start = pid * BLOCK_SIZE\n",
    "    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n",
    "    mask = offsets < num_elements\n",
    "\n",
    "    x = tl.load(x_ptr + offsets, mask)\n",
    "\n",
    "    mantissa = libdevice.frexp(x, exp_ptr + offsets)\n",
    "\n",
    "    tl.store(mantissa_ptr + offsets, mantissa, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MLIR_ENABLE_DUMP=1\n",
      "env: MLIR_DUMP_PATH=dump_2.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1,  0,  0, -5, -1,  0, -1, -2,  0, -1, -4], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor([0.6389, 0.7433, 0.8156, 0.9996, 0.9641, 0.9541, 0.7813, 0.5511, 0.5693,\n",
      "        0.9449, 0.9709], device='cuda:0')\n",
      "tensor([-1,  0,  0, -5, -1,  0, -1, -2,  0, -1, -4], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor([0.6389, 0.7433, 0.8156, 0.9996, 0.9641, 0.9541, 0.7813, 0.5511, 0.5693,\n",
      "        0.9449, 0.9709], device='cuda:0', dtype=torch.float64)\n",
      "The maximum difference between torch and triton is 2.574586854819927e-08\n"
     ]
    }
   ],
   "source": [
    "%env MLIR_ENABLE_DUMP=1\n",
    "%env MLIR_DUMP_PATH=dump_2.txt\n",
    "!rm -rf ~/.triton\n",
    "\n",
    "#torch.manual_seed(0)\n",
    "size = 11\n",
    "x = torch.rand(size, device=DEVICE, dtype=torch.float64)\n",
    "exp_ptr = torch.zeros(size, device=DEVICE, dtype=torch.int32)\n",
    "mantissa_ptr = torch.zeros(size, device=DEVICE)\n",
    "\n",
    "grid = lambda meta: (triton.cdiv(size, meta['BLOCK_SIZE']), )\n",
    "frexp_real[grid](x, exp_ptr, mantissa_ptr, size, 2)\n",
    "\n",
    "print(exp_ptr)\n",
    "print(mantissa_ptr)\n",
    "\n",
    "torch_mantissa, torch_exp = torch.frexp(x)\n",
    "\n",
    "print(torch_exp)\n",
    "print(torch_mantissa)\n",
    "\n",
    "print(f'The maximum difference between torch and triton is '\n",
    "      f'{torch.max(torch.max(torch.abs(torch_mantissa - mantissa_ptr)), torch.max(torch.abs(torch_exp - exp_ptr)))}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
